{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w:       2.9 | b:       0.5 | cost: 45.660004\n",
      "w_grad:      44.8 | b_grad:      12.4| cost: 45.660004\n",
      "\n",
      "w:     2.452 | b:     0.376 | cost: 26.608435\n",
      "w_grad:      34.2 | b_grad:     9.464| cost: 26.608435\n",
      "\n",
      "w:      2.11 | b:    0.2814 | cost: 15.506124\n",
      "w_grad:     26.11 | b_grad:     7.223| cost: 15.506124\n",
      "\n",
      "w:     1.849 | b:    0.2091 | cost:  9.036247\n",
      "w_grad:     19.93 | b_grad:     5.512| cost:  9.036247\n",
      "\n",
      "w:      1.65 | b:     0.154 | cost:  5.265920\n",
      "w_grad:     15.22 | b_grad:     4.206| cost:  5.265920\n",
      "\n",
      "w:     1.497 | b:     0.112 | cost:  3.068760\n",
      "w_grad:     11.62 | b_grad:     3.209| cost:  3.068760\n",
      "\n",
      "w:     1.381 | b:   0.07987 | cost:  1.788364\n",
      "w_grad:     8.868 | b_grad:     2.448| cost:  1.788364\n",
      "\n",
      "w:     1.293 | b:    0.0554 | cost:  1.042213\n",
      "w_grad:      6.77 | b_grad:     1.867| cost:  1.042213\n",
      "\n",
      "w:     1.225 | b:   0.03673 | cost:  0.607393\n",
      "w_grad:     5.169 | b_grad:     1.423| cost:  0.607393\n",
      "\n",
      "w:     1.173 | b:    0.0225 | cost:  0.354001\n",
      "w_grad:     3.946 | b_grad:     1.084| cost:  0.354001\n",
      "\n",
      "w:     1.134 | b:   0.01166 | cost:  0.206336\n",
      "w_grad:     3.013 | b_grad:    0.8259| cost:  0.206336\n",
      "\n",
      "w:     1.104 | b:  0.003398 | cost:  0.120284\n",
      "w_grad:     2.301 | b_grad:    0.6287| cost:  0.120284\n",
      "\n",
      "w:     1.081 | b: -0.002888 | cost:  0.070137\n",
      "w_grad:     1.757 | b_grad:     0.478| cost:  0.070137\n",
      "\n",
      "w:     1.063 | b: -0.007669 | cost:  0.040913\n",
      "w_grad:     1.342 | b_grad:    0.3631| cost:  0.040913\n",
      "\n",
      "w:      1.05 | b:   -0.0113 | cost:  0.023883\n",
      "w_grad:     1.025 | b_grad:    0.2753| cost:  0.023883\n",
      "\n",
      "w:     1.039 | b:  -0.01405 | cost:  0.013958\n",
      "w_grad:    0.7827 | b_grad:    0.2083| cost:  0.013958\n",
      "\n",
      "w:     1.032 | b:  -0.01614 | cost:  0.008174\n",
      "w_grad:     0.598 | b_grad:    0.1572| cost:  0.008174\n",
      "\n",
      "w:     1.026 | b:  -0.01771 | cost:  0.004804\n",
      "w_grad:     0.457 | b_grad:    0.1182| cost:  0.004804\n",
      "\n",
      "w:     1.021 | b:  -0.01889 | cost:  0.002839\n",
      "w_grad:    0.3494 | b_grad:   0.08841| cost:  0.002839\n",
      "\n",
      "w:     1.018 | b:  -0.01977 | cost:  0.001694\n",
      "w_grad:    0.2672 | b_grad:   0.06568| cost:  0.001694\n",
      "\n",
      "w:     1.015 | b:  -0.02043 | cost:  0.001026\n",
      "w_grad:    0.2045 | b_grad:   0.04834| cost:  0.001026\n",
      "\n",
      "w:     1.013 | b:  -0.02091 | cost:  0.000637\n",
      "w_grad:    0.1566 | b_grad:    0.0351| cost:  0.000637\n",
      "\n",
      "w:     1.011 | b:  -0.02127 | cost:  0.000410\n",
      "w_grad:      0.12 | b_grad:     0.025| cost:  0.000410\n",
      "\n",
      "w:      1.01 | b:  -0.02152 | cost:  0.000277\n",
      "w_grad:   0.09213 | b_grad:    0.0173| cost:  0.000277\n",
      "\n",
      "w:     1.009 | b:  -0.02169 | cost:  0.000200\n",
      "w_grad:   0.07082 | b_grad:   0.01143| cost:  0.000200\n",
      "\n",
      "w:     1.008 | b:   -0.0218 | cost:  0.000154\n",
      "w_grad:   0.05456 | b_grad:   0.00695| cost:  0.000154\n",
      "\n",
      "w:     1.008 | b:  -0.02187 | cost:  0.000127\n",
      "w_grad:   0.04214 | b_grad:  0.003538| cost:  0.000127\n",
      "\n",
      "w:     1.007 | b:  -0.02191 | cost:  0.000112\n",
      "w_grad:   0.03265 | b_grad: 0.0009392| cost:  0.000112\n",
      "\n",
      "w:     1.007 | b:  -0.02192 | cost:  0.000102\n",
      "w_grad:   0.02541 | b_grad: -0.001039| cost:  0.000102\n",
      "\n",
      "w:     1.007 | b:  -0.02191 | cost:  0.000096\n",
      "w_grad:   0.01989 | b_grad: -0.002543| cost:  0.000096\n",
      "\n",
      "w:     1.007 | b:  -0.02188 | cost:  0.000093\n",
      "w_grad:   0.01566 | b_grad: -0.003685| cost:  0.000093\n",
      "\n",
      "w:     1.007 | b:  -0.02184 | cost:  0.000090\n",
      "w_grad:   0.01244 | b_grad: -0.004551| cost:  0.000090\n",
      "\n",
      "w:     1.006 | b:   -0.0218 | cost:  0.000089\n",
      "w_grad:  0.009976 | b_grad: -0.005206| cost:  0.000089\n",
      "\n",
      "w:     1.006 | b:  -0.02175 | cost:  0.000087\n",
      "w_grad:  0.008093 | b_grad: -0.005701| cost:  0.000087\n",
      "\n",
      "w:     1.006 | b:  -0.02169 | cost:  0.000087\n",
      "w_grad:  0.006655 | b_grad: -0.006072| cost:  0.000087\n",
      "\n",
      "w:     1.006 | b:  -0.02163 | cost:  0.000086\n",
      "w_grad:  0.005555 | b_grad:  -0.00635| cost:  0.000086\n",
      "\n",
      "w:     1.006 | b:  -0.02157 | cost:  0.000085\n",
      "w_grad:  0.004714 | b_grad: -0.006556| cost:  0.000085\n",
      "\n",
      "w:     1.006 | b:   -0.0215 | cost:  0.000084\n",
      "w_grad:  0.004072 | b_grad: -0.006708| cost:  0.000084\n",
      "\n",
      "w:     1.006 | b:  -0.02143 | cost:  0.000084\n",
      "w_grad:  0.003577 | b_grad: -0.006818| cost:  0.000084\n",
      "\n",
      "w:     1.006 | b:  -0.02137 | cost:  0.000083\n",
      "w_grad:  0.003199 | b_grad: -0.006897| cost:  0.000083\n",
      "\n",
      "w:     1.006 | b:   -0.0213 | cost:  0.000083\n",
      "w_grad:  0.002911 | b_grad:  -0.00695| cost:  0.000083\n",
      "\n",
      "w:     1.006 | b:  -0.02123 | cost:  0.000082\n",
      "w_grad:  0.002688 | b_grad: -0.006986| cost:  0.000082\n",
      "\n",
      "w:     1.006 | b:  -0.02116 | cost:  0.000082\n",
      "w_grad:  0.002514 | b_grad: -0.007008| cost:  0.000082\n",
      "\n",
      "w:     1.006 | b:  -0.02109 | cost:  0.000081\n",
      "w_grad:  0.002381 | b_grad: -0.007018| cost:  0.000081\n",
      "\n",
      "w:     1.006 | b:  -0.02102 | cost:  0.000080\n",
      "w_grad:  0.002278 | b_grad: -0.007021| cost:  0.000080\n",
      "\n",
      "w:     1.006 | b:  -0.02095 | cost:  0.000080\n",
      "w_grad:  0.002199 | b_grad: -0.007017| cost:  0.000080\n",
      "\n",
      "w:     1.006 | b:  -0.02088 | cost:  0.000079\n",
      "w_grad:  0.002137 | b_grad: -0.007009| cost:  0.000079\n",
      "\n",
      "w:     1.006 | b:  -0.02081 | cost:  0.000079\n",
      "w_grad:  0.002088 | b_grad: -0.006996| cost:  0.000079\n",
      "\n",
      "w:     1.006 | b:  -0.02074 | cost:  0.000078\n",
      "w_grad:  0.002048 | b_grad: -0.006982| cost:  0.000078\n",
      "\n",
      "w:     1.006 | b:  -0.02067 | cost:  0.000078\n",
      "w_grad:  0.002017 | b_grad: -0.006965| cost:  0.000078\n",
      "\n",
      "w:     1.006 | b:   -0.0206 | cost:  0.000077\n",
      "w_grad:  0.001991 | b_grad: -0.006947| cost:  0.000077\n",
      "\n",
      "w:     1.006 | b:  -0.02053 | cost:  0.000077\n",
      "w_grad:   0.00197 | b_grad: -0.006927| cost:  0.000077\n",
      "\n",
      "w:     1.006 | b:  -0.02046 | cost:  0.000076\n",
      "w_grad:  0.001953 | b_grad: -0.006907| cost:  0.000076\n",
      "\n",
      "w:     1.006 | b:  -0.02039 | cost:  0.000076\n",
      "w_grad:  0.001937 | b_grad: -0.006886| cost:  0.000076\n",
      "\n",
      "w:     1.006 | b:  -0.02032 | cost:  0.000075\n",
      "w_grad:  0.001922 | b_grad: -0.006865| cost:  0.000075\n",
      "\n",
      "w:     1.006 | b:  -0.02025 | cost:  0.000075\n",
      "w_grad:  0.001912 | b_grad: -0.006843| cost:  0.000075\n",
      "\n",
      "w:     1.006 | b:  -0.02018 | cost:  0.000074\n",
      "w_grad:  0.001904 | b_grad:  -0.00682| cost:  0.000074\n",
      "\n",
      "w:     1.006 | b:  -0.02011 | cost:  0.000074\n",
      "w_grad:  0.001893 | b_grad: -0.006798| cost:  0.000074\n",
      "\n",
      "w:     1.006 | b:  -0.02005 | cost:  0.000073\n",
      "w_grad:  0.001883 | b_grad: -0.006776| cost:  0.000073\n",
      "\n",
      "w:     1.006 | b:  -0.01998 | cost:  0.000073\n",
      "w_grad:  0.001875 | b_grad: -0.006754| cost:  0.000073\n",
      "\n",
      "w:     1.006 | b:  -0.01991 | cost:  0.000072\n",
      "w_grad:  0.001869 | b_grad: -0.006731| cost:  0.000072\n",
      "\n",
      "w:     1.005 | b:  -0.01984 | cost:  0.000072\n",
      "w_grad:  0.001861 | b_grad: -0.006708| cost:  0.000072\n",
      "\n",
      "w:     1.005 | b:  -0.01978 | cost:  0.000071\n",
      "w_grad:  0.001855 | b_grad: -0.006686| cost:  0.000071\n",
      "\n",
      "w:     1.005 | b:  -0.01971 | cost:  0.000071\n",
      "w_grad:  0.001847 | b_grad: -0.006664| cost:  0.000071\n",
      "\n",
      "w:     1.005 | b:  -0.01964 | cost:  0.000070\n",
      "w_grad:   0.00184 | b_grad: -0.006641| cost:  0.000070\n",
      "\n",
      "w:     1.005 | b:  -0.01958 | cost:  0.000070\n",
      "w_grad:  0.001835 | b_grad: -0.006619| cost:  0.000070\n",
      "\n",
      "w:     1.005 | b:  -0.01951 | cost:  0.000069\n",
      "w_grad:  0.001829 | b_grad: -0.006596| cost:  0.000069\n",
      "\n",
      "w:     1.005 | b:  -0.01944 | cost:  0.000069\n",
      "w_grad:  0.001822 | b_grad: -0.006574| cost:  0.000069\n",
      "\n",
      "w:     1.005 | b:  -0.01938 | cost:  0.000068\n",
      "w_grad:  0.001816 | b_grad: -0.006552| cost:  0.000068\n",
      "\n",
      "w:     1.005 | b:  -0.01931 | cost:  0.000068\n",
      "w_grad:   0.00181 | b_grad:  -0.00653| cost:  0.000068\n",
      "\n",
      "w:     1.005 | b:  -0.01925 | cost:  0.000067\n",
      "w_grad:  0.001803 | b_grad: -0.006508| cost:  0.000067\n",
      "\n",
      "w:     1.005 | b:  -0.01918 | cost:  0.000067\n",
      "w_grad:  0.001798 | b_grad: -0.006485| cost:  0.000067\n",
      "\n",
      "w:     1.005 | b:  -0.01912 | cost:  0.000067\n",
      "w_grad:  0.001792 | b_grad: -0.006464| cost:  0.000067\n",
      "\n",
      "w:     1.005 | b:  -0.01905 | cost:  0.000066\n",
      "w_grad:  0.001785 | b_grad: -0.006442| cost:  0.000066\n",
      "\n",
      "w:     1.005 | b:  -0.01899 | cost:  0.000066\n",
      "w_grad:  0.001777 | b_grad:  -0.00642| cost:  0.000066\n",
      "\n",
      "w:     1.005 | b:  -0.01893 | cost:  0.000065\n",
      "w_grad:  0.001773 | b_grad: -0.006398| cost:  0.000065\n",
      "\n",
      "w:     1.005 | b:  -0.01886 | cost:  0.000065\n",
      "w_grad:  0.001765 | b_grad: -0.006377| cost:  0.000065\n",
      "\n",
      "w:     1.005 | b:   -0.0188 | cost:  0.000064\n",
      "w_grad:   0.00176 | b_grad: -0.006355| cost:  0.000064\n",
      "\n",
      "w:     1.005 | b:  -0.01873 | cost:  0.000064\n",
      "w_grad:  0.001753 | b_grad: -0.006334| cost:  0.000064\n",
      "\n",
      "w:     1.005 | b:  -0.01867 | cost:  0.000063\n",
      "w_grad:  0.001748 | b_grad: -0.006313| cost:  0.000063\n",
      "\n",
      "w:     1.005 | b:  -0.01861 | cost:  0.000063\n",
      "w_grad:   0.00174 | b_grad: -0.006292| cost:  0.000063\n",
      "\n",
      "w:     1.005 | b:  -0.01854 | cost:  0.000063\n",
      "w_grad:  0.001735 | b_grad:  -0.00627| cost:  0.000063\n",
      "\n",
      "w:     1.005 | b:  -0.01848 | cost:  0.000062\n",
      "w_grad:   0.00173 | b_grad: -0.006249| cost:  0.000062\n",
      "\n",
      "w:     1.005 | b:  -0.01842 | cost:  0.000062\n",
      "w_grad:  0.001724 | b_grad: -0.006228| cost:  0.000062\n",
      "\n",
      "w:     1.005 | b:  -0.01836 | cost:  0.000061\n",
      "w_grad:  0.001718 | b_grad: -0.006207| cost:  0.000061\n",
      "\n",
      "w:     1.005 | b:  -0.01829 | cost:  0.000061\n",
      "w_grad:  0.001712 | b_grad: -0.006186| cost:  0.000061\n",
      "\n",
      "w:     1.005 | b:  -0.01823 | cost:  0.000061\n",
      "w_grad:  0.001705 | b_grad: -0.006165| cost:  0.000061\n",
      "\n",
      "w:     1.005 | b:  -0.01817 | cost:  0.000060\n",
      "w_grad:  0.001701 | b_grad: -0.006144| cost:  0.000060\n",
      "\n",
      "w:     1.005 | b:  -0.01811 | cost:  0.000060\n",
      "w_grad:  0.001695 | b_grad: -0.006123| cost:  0.000060\n",
      "\n",
      "w:     1.005 | b:  -0.01805 | cost:  0.000059\n",
      "w_grad:  0.001689 | b_grad: -0.006103| cost:  0.000059\n",
      "\n",
      "w:     1.005 | b:  -0.01799 | cost:  0.000059\n",
      "w_grad:  0.001682 | b_grad: -0.006082| cost:  0.000059\n",
      "\n",
      "w:     1.005 | b:  -0.01793 | cost:  0.000058\n",
      "w_grad:  0.001679 | b_grad: -0.006061| cost:  0.000058\n",
      "\n",
      "w:     1.005 | b:  -0.01787 | cost:  0.000058\n",
      "w_grad:  0.001672 | b_grad: -0.006041| cost:  0.000058\n",
      "\n",
      "w:     1.005 | b:  -0.01781 | cost:  0.000058\n",
      "w_grad:  0.001667 | b_grad:  -0.00602| cost:  0.000058\n",
      "\n",
      "w:     1.005 | b:  -0.01775 | cost:  0.000057\n",
      "w_grad:  0.001662 | b_grad:    -0.006| cost:  0.000057\n",
      "\n",
      "w:     1.005 | b:  -0.01769 | cost:  0.000057\n",
      "w_grad:  0.001656 | b_grad:  -0.00598| cost:  0.000057\n",
      "\n",
      "w:     1.005 | b:  -0.01763 | cost:  0.000057\n",
      "w_grad:  0.001651 | b_grad: -0.005959| cost:  0.000057\n",
      "\n",
      "w:     1.005 | b:  -0.01757 | cost:  0.000056\n",
      "w_grad:  0.001647 | b_grad: -0.005939| cost:  0.000056\n",
      "\n",
      "w:     1.005 | b:  -0.01751 | cost:  0.000056\n",
      "w_grad:  0.001641 | b_grad: -0.005919| cost:  0.000056\n",
      "\n",
      "w:     1.005 | b:  -0.01745 | cost:  0.000055\n",
      "w_grad:  0.001633 | b_grad: -0.005899| cost:  0.000055\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_data = [1,2,3,4,5]\n",
    "y_data=[1,2,3,4,5]\n",
    "\n",
    "w= tf.Variable(2.9)\n",
    "b = tf.Variable(0.5)\n",
    "\n",
    "\n",
    "learning_rate = 0.01\n",
    "for i in range(100):\n",
    "    with tf.GradientTape() as tape:\n",
    "        hypothesis = w * x_data + b\n",
    "        cost = tf.reduce_mean(tf.square(hypothesis-y_data))\n",
    "    \n",
    "    w_grad, b_grad = tape.gradient(cost,[w,b])\n",
    "    \n",
    "    print(\"w:{:10.4} | b:{:10.4} | cost:{:10.6f}\".format(w.numpy(),b.numpy(),cost))\n",
    "    print(\"w_grad:{:10.4} | b_grad:{:10.4}| cost:{:10.6f}\".format(w_grad.numpy(),b_grad.numpy(),cost))\n",
    "    print(\"\")\n",
    "    \n",
    "    w.assign_sub(learning_rate*w_grad)\n",
    "    b.assign_sub(learning_rate*b_grad)\n",
    "\n",
    "##print(\"{:10.4}|{:10.4}|{:10.6f}\".format(w.numpy(),b.numpy(),cost))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ab3a6c5ad1e8c4480a05b10b8bb1c2db3bc6360fc5ba5f5bb59c3c79a0ea1185"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
